{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos/Documents/git/fine-tunning-tutorial/.env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 408/408 [00:00<00:00, 21787.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 440M/440M [00:18<00:00, 23.2MB/s] \n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1377 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 36%|███▋      | 500/1377 [00:47<01:23, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5276, 'learning_rate': 3.184458968772695e-05, 'epoch': 1.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1000/1377 [01:35<00:34, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2969, 'learning_rate': 1.3689179375453886e-05, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1377/1377 [02:12<00:00, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 132.5374, 'train_samples_per_second': 83.026, 'train_steps_per_second': 10.39, 'train_loss': 0.3451770347534268, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.3451770347534268, metrics={'train_runtime': 132.5374, 'train_samples_per_second': 83.026, 'train_steps_per_second': 10.39, 'train_loss': 0.3451770347534268, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 42.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.75k/5.75k [00:00<00:00, 20.5MB/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "To be able to use evaluate-metric/glue, you need to install the following dependencies['scikit-learn', 'scipy'] using 'pip install sklearn scipy' for instance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/carlos/Documents/git/fine-tunning-tutorial/fine-tunning.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/carlos/Documents/git/fine-tunning-tutorial/fine-tunning.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mevaluate\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/carlos/Documents/git/fine-tunning-tutorial/fine-tunning.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m metric \u001b[39m=\u001b[39m evaluate\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mglue\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmrpc\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/carlos/Documents/git/fine-tunning-tutorial/fine-tunning.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m metric\u001b[39m.\u001b[39mcompute(predictions\u001b[39m=\u001b[39mpreds, references\u001b[39m=\u001b[39mpredictions\u001b[39m.\u001b[39mlabel_ids)\n",
      "File \u001b[0;32m~/Documents/git/fine-tunning-tutorial/.env/lib/python3.11/site-packages/evaluate/loading.py:748\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    747\u001b[0m download_mode \u001b[39m=\u001b[39m DownloadMode(download_mode \u001b[39mor\u001b[39;00m DownloadMode\u001b[39m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[0;32m--> 748\u001b[0m evaluation_module \u001b[39m=\u001b[39m evaluation_module_factory(\n\u001b[1;32m    749\u001b[0m     path, module_type\u001b[39m=\u001b[39;49mmodule_type, revision\u001b[39m=\u001b[39;49mrevision, download_config\u001b[39m=\u001b[39;49mdownload_config, download_mode\u001b[39m=\u001b[39;49mdownload_mode\n\u001b[1;32m    750\u001b[0m )\n\u001b[1;32m    751\u001b[0m evaluation_cls \u001b[39m=\u001b[39m import_main_class(evaluation_module\u001b[39m.\u001b[39mmodule_path)\n\u001b[1;32m    752\u001b[0m evaluation_instance \u001b[39m=\u001b[39m evaluation_cls(\n\u001b[1;32m    753\u001b[0m     config_name\u001b[39m=\u001b[39mconfig_name,\n\u001b[1;32m    754\u001b[0m     process_id\u001b[39m=\u001b[39mprocess_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minit_kwargs,\n\u001b[1;32m    761\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/git/fine-tunning-tutorial/.env/lib/python3.11/site-packages/evaluate/loading.py:680\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    679\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(e1, (\u001b[39mConnectionError\u001b[39;00m, \u001b[39mFileNotFoundError\u001b[39;00m)):\n\u001b[0;32m--> 680\u001b[0m             \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    681\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    682\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a module script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    683\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist on the Hugging Face Hub either.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/git/fine-tunning-tutorial/.env/lib/python3.11/site-packages/evaluate/loading.py:639\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mfor\u001b[39;00m current_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcomparison\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmeasurement\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    632\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m         \u001b[39mreturn\u001b[39;00m HubEvaluationModuleFactory(\n\u001b[1;32m    634\u001b[0m             \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mevaluate-\u001b[39;49m\u001b[39m{\u001b[39;49;00mcurrent_type\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mpath\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    635\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    636\u001b[0m             download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m    637\u001b[0m             download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m    638\u001b[0m             dynamic_modules_path\u001b[39m=\u001b[39;49mdynamic_modules_path,\n\u001b[0;32m--> 639\u001b[0m         )\u001b[39m.\u001b[39;49mget_module()\n\u001b[1;32m    640\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/git/fine-tunning-tutorial/.env/lib/python3.11/site-packages/evaluate/loading.py:489\u001b[0m, in \u001b[0;36mHubEvaluationModuleFactory.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m    488\u001b[0m imports \u001b[39m=\u001b[39m get_imports(local_path)\n\u001b[0;32m--> 489\u001b[0m local_imports \u001b[39m=\u001b[39m _download_additional_modules(\n\u001b[1;32m    490\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    491\u001b[0m     base_path\u001b[39m=\u001b[39;49mhf_hub_url(path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, revision\u001b[39m=\u001b[39;49mrevision),\n\u001b[1;32m    492\u001b[0m     imports\u001b[39m=\u001b[39;49mimports,\n\u001b[1;32m    493\u001b[0m     download_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_config,\n\u001b[1;32m    494\u001b[0m )\n\u001b[1;32m    495\u001b[0m \u001b[39m# copy the script and the files in an importable directory\u001b[39;00m\n\u001b[1;32m    496\u001b[0m dynamic_modules_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_modules_path \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_modules_path \u001b[39melse\u001b[39;00m init_dynamic_modules()\n",
      "File \u001b[0;32m~/Documents/git/fine-tunning-tutorial/.env/lib/python3.11/site-packages/evaluate/loading.py:265\u001b[0m, in \u001b[0;36m_download_additional_modules\u001b[0;34m(name, base_path, imports, download_config)\u001b[0m\n\u001b[1;32m    263\u001b[0m         needs_to_be_installed\u001b[39m.\u001b[39madd((library_import_name, library_import_path))\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m needs_to_be_installed:\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    266\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTo be able to use \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m, you need to install the following dependencies\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m[lib_name\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mlib_name,\u001b[39m \u001b[39mlib_path\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mneeds_to_be_installed]\u001b[39m}\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpip install \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([lib_path\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mlib_name,\u001b[39m \u001b[39mlib_path\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mneeds_to_be_installed])\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for instance\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[39mreturn\u001b[39;00m local_imports\n",
      "\u001b[0;31mImportError\u001b[0m: To be able to use evaluate-metric/glue, you need to install the following dependencies['scikit-learn', 'scipy'] using 'pip install sklearn scipy' for instance'"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
